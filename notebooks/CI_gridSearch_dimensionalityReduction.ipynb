{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(THIS TUTORIAL IS STILL BEING DEVELOPED DEVELOPMENT) \n",
    "\n",
    "Add description here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import (loadmat, savemat)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif, chi2\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "from mne.datasets import sample\n",
    "from mne.decoding import (SlidingEstimator, GeneralizingEstimator,\n",
    "                          cross_val_multiscore, LinearModel, get_coef)\n",
    "from sklearn.preprocessing import LabelEncoder            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scorer(y_true, y_pred):\n",
    "    # Probabilistic estimates are reported for each class. In our case \n",
    "    # `y_pred` shape is (n_trials, 2), where `y[:, 0] = 1 - y[:, 1]`.\n",
    "    return roc_auc_score(y_true, y_pred[:, 1]) \n",
    "\n",
    "## This code is meant to work on WINDOWS. Giulia has a version that works on MAC. \n",
    "def load_cor(xDir, var_name='struct_cor'):\n",
    "    import mne\n",
    "    from mne import create_info\n",
    "    from mne.epochs import EpochsArray\n",
    "    import scipy.io as sio\n",
    "    import numpy as np\n",
    "    # load Matlab/Fieldtrip data\n",
    "    mat = sio.loadmat(xDir, squeeze_me=True, struct_as_record=False)\n",
    "    ft_data = mat[var_name]\n",
    "    event = ft_data.trialinfo[:, 1]\n",
    "\n",
    "    # convert to mne\n",
    "    n_trial, n_chans, n_time = ft_data.trial.shape\n",
    "    data = np.zeros((n_trial, n_chans, n_time))\n",
    "    data = ft_data.trial\n",
    "\n",
    "    sfreq = 200\n",
    "    time = ft_data.time\n",
    "\n",
    "    \n",
    "    coi = range(n_chans)\n",
    "    data = data[:, coi, :]\n",
    "    chan_names = [l.encode('ascii') for l in ft_data.label[coi]]\n",
    "    chan_types = ft_data.label[coi]\n",
    "    chan_types[:] = 'eeg'\n",
    "    info = create_info(chan_names, sfreq, chan_types)\n",
    "    events = np.array([np.arange(n_trial), np.zeros(n_trial), event], int).T\n",
    "    epochs = EpochsArray(data, info, events=events,\n",
    "                         tmin=np.min(time), verbose=False)\n",
    "    montage = mne.channels.read_montage('GSN-HydroCel-257')\n",
    "    epochs.set_montage(montage)\n",
    "    return epochs, ft_data.trialinfo\n",
    "    \n",
    "\n",
    "## This function is the proper gridsearch function.\n",
    "# mainPath = path of your CI\\Python\\Subjects folder\n",
    "# name = name of your subject\n",
    "# varname = name of the type of data. Can be _cor or _inter\n",
    "# N_features = number of features to be tested\n",
    "# c_options = values of C to be tested\n",
    "def grid_dim_red(mainPath, name, varname, N_FEATURES_OPTIONS, C_OPTIONS):\n",
    "\n",
    "    print('working on subject ' + name)\n",
    "    \n",
    "    # This is the same as the decoding script\n",
    "    filePath = mainPath + name + '\\\\'\n",
    "    #loading labels for conditions\n",
    "    yDir = filePath + 'trl_conditions.mat'\n",
    "    Y = loadmat(yDir)\n",
    "    conditions = Y['trl_conditions']\n",
    "    Y = conditions.transpose().ravel()\n",
    "    Y[Y==-1] = 0\n",
    "    \n",
    "    #loading data as epoch object\n",
    "    print('loading data...')\n",
    "    xDir = filePath + varname + '.mat'\n",
    "    epochs, _ = load_cor(xDir, var_name=varname)\n",
    "    \n",
    "    #Retrieving data as matrix\n",
    "    data = epochs.get_data()\n",
    "    X = np.reshape(data, [data.shape[0], data.shape[1]*data.shape[2]])\n",
    "    \n",
    "    \n",
    "    # Here we test three different Dim_red techniques:\n",
    "    # - PCA\n",
    "    # - Univariate feature reduction\n",
    "    # - KClustering\n",
    "    print('defining reduction techniques')\n",
    "    param_grid = [\n",
    "        {\n",
    "            'reduce_dim': [PCA(iterated_power=7)],\n",
    "            'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "            'classify__C': C_OPTIONS\n",
    "        },  \n",
    "        {\n",
    "            'reduce_dim': [SelectKBest(f_classif)],\n",
    "            'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "            'classify__C': C_OPTIONS\n",
    "        },  \n",
    "        {\n",
    "            'reduce_dim': [MiniBatchKMeans()],\n",
    "            'reduce_dim__n_clusters': N_FEATURES_OPTIONS,\n",
    "            'classify__C': C_OPTIONS\n",
    "        },     \n",
    "        \n",
    "    ]\n",
    "    reducer_labels = ['PCA', 'KBest(f_classif)', 'Clustering (K-means)']\n",
    "    \n",
    "    # This is the pipeline for your classifier. \n",
    "    # the 'reduce_dim' field will change according to\n",
    "    # what you have previously specified in param_grid\n",
    "    pipe = Pipeline([\n",
    "        ('scaling', StandardScaler()),\n",
    "        ('reduce_dim', SelectKBest(f_classif)),\n",
    "        ('classify',  SVC(class_weight='balanced', probability=False, kernel='linear'))\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # Defining cv folds parameter\n",
    "    inner_cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    print('training gridsearch')\n",
    "    grid = GridSearchCV(pipe, cv=inner_cv, n_jobs=1, param_grid=param_grid, scoring='roc_auc')\n",
    "    \n",
    "    grid.fit(X, Y)\n",
    "    \n",
    "    print('saving results')\n",
    "    reduction_results = np.array(grid.cv_results_['mean_test_score'])\n",
    "    np.save(filePath + 'reduction_results', reduction_results) \n",
    "    return grid, reduction_results\n",
    "\n",
    "\n",
    "# This functions plots the results of the gridsearch\n",
    "def plot_dimcomp(mean_scores=reduction_results):\n",
    "    \n",
    "    # scores are in the order of param_grid iteration, which is alphabetical\n",
    "    mean_scores = mean_scores.reshape(len(C_OPTIONS), -1, len(N_FEATURES_OPTIONS))\n",
    "    # select score for best C\n",
    "    mean_scores = mean_scores.max(axis=0)\n",
    "    bar_offsets = (np.arange(len(N_FEATURES_OPTIONS)) *\n",
    "                   (len(reducer_labels) + 1) + .5)\n",
    "\n",
    "    plt.figure()\n",
    "    COLORS = 'bgrcmyk'\n",
    "    for i, (label, reducer_scores) in enumerate(zip(reducer_labels, mean_scores)):\n",
    "        plt.bar(bar_offsets + i, reducer_scores, label=label, color=COLORS[i])\n",
    "\n",
    "    plt.title(\"Comparing feature reduction techniques\")\n",
    "    plt.xlabel('Reduced number of features')\n",
    "    plt.xticks(bar_offsets + len(reducer_labels) / 2, N_FEATURES_OPTIONS)\n",
    "    plt.ylabel('Digit classification AUC')\n",
    "    plt.ylim((0, 1))\n",
    "    plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subject = os.listdir('C:\\\\Users\\\\Ana\\\\Desktop\\\\CI\\\\Python\\\\Subjects')\n",
    "subject = np.sort(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on subject DB171120v03HT\n",
      "loading data...\n",
      "defining reduction techniques\n",
      "training gridsearch\n",
      "saving results\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES_OPTIONS = [10, 20, 30, 40, 50, 60, 10]\n",
    "C_OPTIONS = [1]\n",
    "\n",
    "grid, reduction_results = grid_dim_red('C:\\\\Users\\\\Ana\\\\Desktop\\\\CI\\\\Python\\\\Subjects\\\\', 'DB171120v03HT', 'struct_cor', N_FEATURES_OPTIONS, C_OPTIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'param_grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-1ddac0de6e86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m        \u001b[1;33m(\u001b[0m\u001b[1;34m'classify'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m    ])\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'param_grid' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
